{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks.tracker import *\n",
    "from fastai.text import *\n",
    "from fastai.tabular import *\n",
    "from fastai_tab_text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "reset_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercari_path = Path('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```text\n",
      "=== Software === \n",
      "python        : 3.7.1\n",
      "fastai        : 1.0.51\n",
      "fastprogress  : 0.1.19\n",
      "torch         : 1.0.0\n",
      "nvidia driver : 410.104\n",
      "torch cuda    : 9.0.176 / is available\n",
      "torch cudnn   : 7401 / is enabled\n",
      "\n",
      "=== Hardware === \n",
      "nvidia gpus   : 1\n",
      "torch devices : 1\n",
      "  - gpu0      : 8116MB | GeForce GTX 1080\n",
      "\n",
      "=== Environment === \n",
      "platform      : Linux-4.15.0-47-generic-x86_64-with-debian-stretch-sid\n",
      "distro        : #50~16.04.1-Ubuntu SMP Fri Mar 15 16:06:21 UTC 2019\n",
      "conda env     : python37\n",
      "python        : /home/quantran/anaconda3/envs/python37/bin/python\n",
      "sys.path      : \n",
      "/home/quantran/kwon/kaggle/mercari\n",
      "/home/quantran/anaconda3/envs/python37/lib/python37.zip\n",
      "/home/quantran/anaconda3/envs/python37/lib/python3.7\n",
      "/home/quantran/anaconda3/envs/python37/lib/python3.7/lib-dynload\n",
      "/home/quantran/anaconda3/envs/python37/lib/python3.7/site-packages\n",
      "/home/quantran/anaconda3/envs/python37/lib/python3.7/site-packages/IPython/extensions\n",
      "/home/quantran/.ipython\n",
      "```\n",
      "\n",
      "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
      "\n",
      "Optional package(s) to enhance the diagnostics can be installed with:\n",
      "pip install distro\n",
      "Once installed, re-run this utility to get the additional information\n"
     ]
    }
   ],
   "source": [
    "from fastai.utils.collect_env import show_install\n",
    "show_install()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  \n",
    "    df['category_name'] = df['category_name'].fillna('//')\n",
    "    df['category1'] = df['category_name'].apply(lambda x : x.split('/')[0].strip())\n",
    "    df.loc[df.category1=='','category1']= np.NaN\n",
    "    df['category2'] = df['category_name'].apply(lambda x : x.split('/')[1].strip())\n",
    "    df.loc[df.category2=='','category2']= np.NaN\n",
    "    df['category3'] = df['category_name'].apply(lambda x : x.split('/')[2].strip())\n",
    "    df.loc[df.category3=='','category3']= np.NaN\n",
    "    df['category_name'] = df['category_name'].apply( lambda x : ' '.join( x.split('/') ).strip() )\n",
    "    df.loc[df.category_name=='','category_name']= 'No category' # let this info in when concatenating text for RNN\n",
    "    \n",
    "    df_bn_fillna = df['brand_name'].fillna('No brand')\n",
    "    df['text'] = (df['name'].fillna('No name') + '. ' + df_bn_fillna + '. ' + \n",
    "                  df['category_name'] + '. ' + df['item_description'].fillna('No description'))\n",
    "    return df[['category1','category2','category3','brand_name', 'text', 'shipping', 'item_condition_id','price']]\n",
    "\n",
    "def preprocess_all(sample=None):\n",
    "    train = pd.read_table(mercari_path/'train.tsv').drop('train_id',axis=1)\n",
    "    price = train.price.values\n",
    "    train=train.drop('price',axis=1)\n",
    "    train['price']=price\n",
    "    \n",
    "    test = pd.read_table(mercari_path/'test_stg2.tsv').drop('test_id',axis=1)\n",
    "    test['price'] = np.NAN\n",
    "    train = train[train['price'] > 0].reset_index(drop=True)\n",
    "    all_df = pd.concat([train,test],axis=0).reset_index(drop=True)\n",
    "    del train\n",
    "    del test\n",
    "    gc.collect()\n",
    "\n",
    "    all_df = preprocess_text_cols(all_df)\n",
    "    train_df = all_df[~all_df.price.isnull()]\n",
    "    test_df = all_df[all_df.price.isnull()]\n",
    "    del all_df\n",
    "    gc.collect()\n",
    "    \n",
    "    if sample:\n",
    "        np.random.seed(42)\n",
    "        sample = np.random.permutation(sample)\n",
    "        train_df = train_df.loc[sample].reset_index(drop=True)\n",
    "        \n",
    "    test_df= test_df.drop('price',axis=1)    \n",
    "    return train_df,test_df\n",
    "\n",
    "def preprocess_train(sample=None):\n",
    "    train = pd.read_table(mercari_path/'train.tsv').drop('train_id',axis=1)\n",
    "    price = train.price.values\n",
    "    train=train.drop('price',axis=1)\n",
    "    train['price']=price\n",
    "\n",
    "    if sample:\n",
    "        np.random.seed(42)\n",
    "        sample = np.random.permutation(sample)\n",
    "        train = train.loc[sample].reset_index(drop=True)\n",
    "\n",
    "    train = preprocess_text_cols(train)\n",
    "\n",
    "    return train\n",
    "def get_val_idxs(train,n_splits=20):\n",
    "    np.random.seed(42)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    train_idxs, valid_idxs = next(cv.split(train))\n",
    "    return train_idxs,valid_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1482535 # train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df,test_df = preprocess_all(int(0.01*n))\n",
    "\n",
    "# train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = preprocess_train(int(0.01*n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482535, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = preprocess_train()\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category1', 'category2', 'category3', 'brand_name', 'text', 'shipping',\n",
       "       'item_condition_id', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.price = np.log1p(train_df['price']) # so we can use MSE in NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>text</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauty</td>\n",
       "      <td>Makeup</td>\n",
       "      <td>Lips</td>\n",
       "      <td>SeneGence</td>\n",
       "      <td>LipSense bundle FOR Moomoo's sister ;). SeneGe...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.094345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Pumps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silver Prom Shoes. No brand. Women Shoes Pumps...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.772589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women</td>\n",
       "      <td>Pants</td>\n",
       "      <td>Casual Pants</td>\n",
       "      <td>Eileen Fisher</td>\n",
       "      <td>Eileen Fisher organic cotton pants 1X. Eileen ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.204693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women</td>\n",
       "      <td>Tops &amp; Blouses</td>\n",
       "      <td>T-Shirts</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Adorable Adidas Crop Top White for Karen. Adid...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.044522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women</td>\n",
       "      <td>Tops &amp; Blouses</td>\n",
       "      <td>Tank, Cami</td>\n",
       "      <td>Brandy Melville</td>\n",
       "      <td>Brandy Melville Front-Tie Tank Top. Brandy Mel...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.564949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category1       category2     category3       brand_name  \\\n",
       "0    Beauty          Makeup          Lips        SeneGence   \n",
       "1     Women           Shoes         Pumps              NaN   \n",
       "2     Women           Pants  Casual Pants    Eileen Fisher   \n",
       "3     Women  Tops & Blouses      T-Shirts           Adidas   \n",
       "4     Women  Tops & Blouses    Tank, Cami  Brandy Melville   \n",
       "\n",
       "                                                text  shipping  \\\n",
       "0  LipSense bundle FOR Moomoo's sister ;). SeneGe...         0   \n",
       "1  Silver Prom Shoes. No brand. Women Shoes Pumps...         1   \n",
       "2  Eileen Fisher organic cotton pants 1X. Eileen ...         0   \n",
       "3  Adorable Adidas Crop Top White for Karen. Adid...         0   \n",
       "4  Brandy Melville Front-Tie Tank Top. Brandy Mel...         0   \n",
       "\n",
       "   item_condition_id     price  \n",
       "0                  1  4.094345  \n",
       "1                  2  2.772589  \n",
       "2                  1  4.204693  \n",
       "3                  2  3.044522  \n",
       "4                  1  2.564949  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silver Prom Shoes. No brand. Women Shoes Pumps. Only worn once, about a 3 inch heel'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.text.head()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of continuous feas: 1\n",
      "# of categorical feas: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_names=['category1','category2','category3','brand_name','shipping']\n",
    "# cont_names= list(set(train.columns) - set(cat_names) - {'AdoptionSpeed'})\n",
    "cont_names= list(set(train_df.columns) - set(cat_names) - {'price','text'})\n",
    "print(f'# of continuous feas: {len(cont_names)}')\n",
    "print(f'# of categorical feas: {len(cat_names)}')\n",
    "dep_var = 'price'\n",
    "procs = [FillMissing,Categorify, Normalize]\n",
    "\n",
    "txt_cols=['text']\n",
    "\n",
    "len(cat_names) + len(cont_names) + 2 == train_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2,     3, ..., 14821, 14822, 14823, 14824]),\n",
       " array([   19,    27,    47,    99, ..., 14766, 14777, 14791, 14815]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((14083,), (742,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs,val_idxs = get_val_idxs(train_df,n_splits=20)\n",
    "train_idxs,val_idxs\n",
    "train_idxs.shape,val_idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tabulartext_databunch(bs=100,val_idxs=val_idxs,path=mercari_path):\n",
    "    data_lm = load_data(path, 'data_lm.pkl', bs=bs)\n",
    "    collate_fn = partial(mixed_tabular_pad_collate, pad_idx=1, pad_first=True)\n",
    "    reset_seed()\n",
    "    return (TabularTextList.from_df(train_df, cat_names, cont_names, txt_cols, vocab=data_lm.vocab, procs=procs, path=path)\n",
    "                            .split_by_idx(val_idxs)\n",
    "                            .label_from_df(cols=dep_var)\n",
    "#                             .add_test(TabularTextList.from_df(test_df, cat_names, cont_names, txt_cols,path=path))\n",
    "                            .databunch(bs=bs,collate_fn=collate_fn, no_check=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'bs60-awdlstm-enc-stage2'\n",
    "def get_tabtext_lr_find(data,params,seed=42):\n",
    "    reset_seed(seed)\n",
    "    learn_lf = tabtext_learner(data,AWD_LSTM,metrics=[root_mean_squared_error],**params).to_fp16()\n",
    "    learn_lf.load_encoder(encoder_name)\n",
    "    return learn_lf.to_fp32()\n",
    "\n",
    "def get_tabulartext_learner(data,params,seed=42):\n",
    "    reset_seed(seed)\n",
    "    learn= tabtext_learner(data,AWD_LSTM,metrics=[root_mean_squared_error],\n",
    "                               callback_fns=[partial(SaveModelCallback, monitor='root_mean_squared_error',mode='min',every='improvement',name='best_nn')],\n",
    "                               **params).to_fp16() # because the language model is trained in fp16\n",
    "    learn.load_encoder(encoder_name)\n",
    "    return learn.to_fp32()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - stage 1 (train head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'layers':[500,400,200],\n",
    "    'bptt':70,\n",
    "    'max_len':20*70,\n",
    "    'drop_mult': 1., # drop_mult: multiply to different dropouts in AWD LSTM\n",
    "    'lin_ftrs': [300],\n",
    "    'ps_lin_ftrs': [0],\n",
    "    'ps': [0.001,0,0],\n",
    "    'emb_drop': 0.,\n",
    "    'y_range': [0,6],\n",
    "    'use_bn': True,    \n",
    "}\n",
    "bs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tabular text databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_tabulartext_databunch(bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TABULAR:<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>#na#</td>\n",
       "      <td>#na#</td>\n",
       "      <td>#na#</td>\n",
       "      <td>FOREVER 21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vintage &amp; Collectibles</td>\n",
       "      <td>Serving</td>\n",
       "      <td>Mug</td>\n",
       "      <td>#na#</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0018</td>\n",
       "      <td>2.8332133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Women</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Knee-Length</td>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0018</td>\n",
       "      <td>2.8332133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Beauty</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>Origins</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0018</td>\n",
       "      <td>2.7080503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Women</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>Crewneck</td>\n",
       "      <td>PINK</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2042</td>\n",
       "      <td>3.0910425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TEXT:<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxeos(3) xxup(6) purple(287) listing(262) xxup(6) iced(4084) xxup(6) 0(217) xxup(6) to(24) xxup(6) n't(118) ,(10) xxrep(7) purple(287) listing(262) ,(10) xxup(6) brand(12) sugar(1104) ,(10) xxup(6) skinny(331) use(215) iced(4084) 0(217) ,(10) xxup(6) home(57) they(148) ,(10) xxup(6) not(74) shipping(41)</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxeos(3) xxup(6) tag(270) xxup(6) xs(273) xxup(6) swamp(8561) yoga(743) ,(10) xxup(6) brand(12) and(13) ,(10) xxup(6) cell(143) the(17) xxup(6) 100(175) xxup(6) stored(2245) xxup(6) yoga(743) ,(10) xxup(6) and(13) in(22) xxup(6) makeup(54) of(28) -(18) soon(1521) ask(197) pink(38) t(70) got(595) ,(10) :(31) daily(517) up(114) true(499) /(29) -(18) xxrep(7) lanc√¥me(3278) box(99) too(211) slip(647) generation(1607) ,(10) xxup(6) 39(2926) no(11) :(31) really(458) came(1270) up(114) it(34) athletic(66) men(64) lips(258) no(11) a(20) sand(2126) with(25) household(1997) size(23) women(14) see(200) strap(489) pink(38) t(70) me(93) keep(600) 's(26) 6(88) brown(289) ,(10) xxup(6) do(109) pink(38) accessories(49) wax(1118) size(23) are(48) lines(1876) :(31) tags(105) deals(945) with(25) light(178) it(34) ](42) fits(224) #(134) ;(414) please(94) come(360) size(23) fees(1432)</td>\n",
       "      <td>2.8332133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxeos(3) xxup(6) casual(987) month(854) 18(390) so(125) &amp;(16) &amp;(16) xxup(6) to(24) shoes(61) women(14) ,(10) xxrep(7) loss(1717) xxup(6) !(15) xxup(6) been(171) xxup(6) phone(226) for(19) xxup(6) excellent(204) ,(10) xxup(6) casual(987) month(854) 18(390) so(125) &amp;(16) &amp;(16) xxup(6) to(24) shoes(61) women(14) shipped(493) save(177) ,(10) xxup(6) have(77) /(29) includes(240) to(24) ,(10) xxup(6) -(18) shipped(493) to(24) of(28) athletic(66) bluetooth(866) skirt(431) ,(10) xxup(6) let(413)</td>\n",
       "      <td>2.8332133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxeos(3) xxup(6) finished(4118) nordstrom(1763) jenner(1630) 2016(1321) firm(120) ,(10) xxup(6) finished(4118) ,(10) xxup(6) rm(45) xxup(6) back(168) xxup(6) skin(167) xxup(6) just(133) ,(10) xxup(6) in(22) will(69)</td>\n",
       "      <td>2.7080503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxeos(3) xxup(6) suede(795) ((39) ,(10) xxrep(7) ((39) ,(10) xxup(6) !(15) xxup(6) both(264) xxup(6) suede(795) ,(10) xxup(6)</td>\n",
       "      <td>3.0910425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tabular text learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = get_tabulartext_learner(data,params,seed=42).to_fp32()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialMultipleInput(\n",
       "  (0): MultiBatchMixEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(33781, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(33781, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearTabularTextClassifier(\n",
       "    (rnn_lin_layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.4)\n",
       "      (2): Linear(in_features=1200, out_features=300, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(11, 6)\n",
       "      (1): Embedding(114, 23)\n",
       "      (2): Embedding(868, 71)\n",
       "      (3): Embedding(4750, 183)\n",
       "      (4): Embedding(3, 3)\n",
       "    )\n",
       "    (emb_drop): Dropout(p=0.0)\n",
       "    (bn_cont): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=587, out_features=500, bias=True)\n",
       "      (1): ReLU(inplace)\n",
       "      (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.001)\n",
       "      (4): Linear(in_features=500, out_features=400, bias=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): Linear(in_features=400, out_features=200, bias=True)\n",
       "      (8): ReLU(inplace)\n",
       "      (9): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 6:51:07 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>root_mean_squared_error</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.308574</th>\n",
       "    <th>0.297962</th>\n",
       "    <th>0.543225</th>\n",
       "    <th>1:08:28</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.322636</th>\n",
       "    <th>0.325656</th>\n",
       "    <th>0.565951</th>\n",
       "    <th>1:08:32</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.308093</th>\n",
       "    <th>0.320362</th>\n",
       "    <th>0.561940</th>\n",
       "    <th>1:08:28</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.301868</th>\n",
       "    <th>0.287178</th>\n",
       "    <th>0.532738</th>\n",
       "    <th>1:08:28</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.287716</th>\n",
       "    <th>0.280896</th>\n",
       "    <th>0.527114</th>\n",
       "    <th>1:08:32</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.283715</th>\n",
       "    <th>0.277816</th>\n",
       "    <th>0.523942</th>\n",
       "    <th>1:08:35</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with root_mean_squared_error value: 0.543224573135376.\n",
      "Better model found at epoch 3 with root_mean_squared_error value: 0.5327377915382385.\n",
      "Better model found at epoch 4 with root_mean_squared_error value: 0.5271139144897461.\n",
      "Better model found at epoch 5 with root_mean_squared_error value: 0.5239419341087341.\n"
     ]
    }
   ],
   "source": [
    "# train on all data from training. Took a whole night\n",
    "learn.fit_one_cycle(6,max_lr=1e-02,pct_start=0.3,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('full2-stage1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: train all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _=learn.load('full2-stage1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(2,max_lr=slice(?,?),pct_start=0.3,moms=(0.8,0.7))\n",
    "\n",
    "# learn.save('full2-unfreeze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not enough memory for this task\n",
    "# params={\n",
    "#     'layers':[500,400,200],\n",
    "#     'bptt':70,\n",
    "#     'max_len':20*70,\n",
    "#     'drop_mult': 1., # drop_mult: multiply to different dropouts in AWD LSTM\n",
    "#     'lin_ftrs': [300],\n",
    "#     'ps_lin_ftrs': [0],\n",
    "#     'ps': [0.001,0,0],\n",
    "#     'emb_drop': 0.,\n",
    "#     'y_range': [0,6],\n",
    "#     'use_bn': True,    \n",
    "# }\n",
    "# bs=100\n",
    "\n",
    "# data = get_tabulartext_databunch(bs=bs)\n",
    "\n",
    "# learn = get_tabulartext_learner(data,params,seed=42).to_fp32()\n",
    "# gc.collect()\n",
    "\n",
    "# _=learn.load('full2-stage1')\n",
    "\n",
    "# test_pred=np.squeeze(to_np(learn.get_preds(DatasetType.Test)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
